As our robots need to operate and interact with people in a dynamic environment, we decided to upgrade our robots’ people detection skills to a generalized system capable of recognizing people in 3D. 
\\
In the people recognition stack, a RGB-D camera is used as the sensor to capture the scene information. A recognition sequence is completed in four steps. First, people are detected in the scene using OpenPose and if their faces were learnt by the robot, then they are recognized using OpenFace. The detections from OpenPose are associated with the recognitions from OpenFace by maximizing the IoUs of the face ROIs. Then, additional properties, such as age, gender and the shirt color, for each of the recognized people are identified. Furthermore, the pose keypoints of these recognitions are coupled with the depth information of the scene to re-project the recognized people to 3D as skeletons. Finally, information about the posture of each 3D skeleton is calculated using geometrical heuristics. This allows for the addition of properties such as “pointing pose” and additional flags such as “is\_ waving”, “is\_ sitting”, etc.
\\
The current design of our people recognition stack is a loosely coupled one and in the future we plan to completely decouple the individual components as most challenges do not require all the information generated by this system.

\begin{figure}[H]
	\centering
    \includegraphics[width=0.7\linewidth]{pointing_pose}
	\caption{The person detection pipeline}
	\label{fig:people_recognition}
\end{figure}