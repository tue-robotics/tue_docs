ED enables integrating sensors through the use of the plugins present in the \textit{ed\_sensor\_integration} package.
Two different plugins exist:
\begin{enumerate}
\item \emph{laser\_plugin}: Enables tracking of 2D laser clusters. This plugin can be used to track dynamic obstacles such as humans.
\item \emph{kinect\_plugin}: Enables world model updates with use of data from a RGBD camera. This plugin exposes several ROS services that realize different functionalities:
\begin{enumerate}[label=(\alph*)]
\item \emph{Segment}: A service that segments sensor data that is not associated with other world model entities. Segmentation areas can be specified per entity in the scene. This allows to segment object `on-top-of’ or ‘in’ a cabinet. All points outside the segmented area are ignore for segmentation.
\item \emph{FitModel}: A service that fits the specified model in the sensor data of a RGBD camera. This allows updating semi-static obstacles such as tables and chairs.
\end{enumerate}
\end{enumerate}

The \emph{ed\_sensor\_integration} plugins enable updating and creating entities. However, new entities are classified as unknown entities. Classification is done in \emph{ed\_perception} plugin\footnote{\url{https://github.com/tue-robotics/ed_perception}} package. 